{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/header.png\"></center>\n",
    "\n",
    "<h1><center>Алгоритмы интеллектуальной обработки больших объемов данных</center></h1>\n",
    "<hr>\n",
    "<h2><center>SVM, Kernel Trick (практика)</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `select_model` принимает на вход обучающую выборку и возвращает модель (машину опорных векторов) с наилучшими параметрами для данной выборки. Эту функцию нужно реализовать.\n",
    "\n",
    "Подбираемые параметры подели включают в себя:\n",
    "- различные функции ядра (линейное, RBF, полиномиальные разных степеней)\n",
    "- различные значения константы $C$ ($0, 0.1, 1, 10, 100, 1000, 10000$)\n",
    "\n",
    "Подбирать параметры необходимо с помощью 10-fold кросс-валидации. Сейчас в качестве заглушки функция всегда возвращает линейный SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(x, y):\n",
    "    \"\"\"\n",
    "    Implement some model selection strategy here:\n",
    "    seek through different kernels and parameters.\n",
    "\n",
    "    Use a validation scheme to select the best model\n",
    "    \n",
    "    Quality metric: accuracy\n",
    "\n",
    "    Returns:\n",
    "        SVM classifier implemented by sklearn SVC class.\n",
    "    \"\"\"\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    \n",
    "    kernel = 'linear'\n",
    "\n",
    "    model = SVC(kernel=kernel)\n",
    "    print(\"Trying model %s\" % model)\n",
    "    \n",
    "    accuracy = np.mean(cross_val_score(model, x, y))\n",
    "\n",
    "    best_model = model\n",
    "    best_accuracy = accuracy\n",
    "    \n",
    "    best_model.fit(x, y)\n",
    "    print(\"Best model %s, with accuracy %f\" % (best_model, best_accuracy))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее две вспомогательные функции, которые отображают данные и разделяющую поверхность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_set(x, y, description=''):\n",
    "    print(\"Plotting data set points\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    colors = np.array(['r', 'b'])[y]\n",
    "    plt.title(description, fontsize='small')\n",
    "    plt.scatter(x[:, 0], x[:, 1], marker='o', c=colors, s=50)\n",
    "    \n",
    "def plot_decision_region(x1_min, x2_min, x1_max, x2_max, clf, n_points=1000):\n",
    "    print(\"Plotting decision region\")\n",
    "    x1, x2 = np.meshgrid(np.linspace(x1_min, x1_max, n_points), np.linspace(x2_min, x2_max, n_points))\n",
    "    z = clf.decision_function(np.c_[x1.ravel(), x2.ravel()]).reshape(x1.shape)\n",
    "\n",
    "    plt.contour(x1, x2, z, levels=[0.0], linestyles='solid', linewidths=2.0)\n",
    "    plt.contour(x1, x2, z, levels=[-1.0, 1.0], linestyles='dashed', linewidths=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linear(size=100, k=1.1, b=0.0, nl=0.1):\n",
    "    print(\"Generating 'Linearly-separated' data set\")\n",
    "\n",
    "    x = np.random.random((size, 2))\n",
    "    y = np.zeros(size, dtype=int)\n",
    "    noise = np.random.randn(size) * nl\n",
    "    y[x[:, 1] - (k * x[:, 0] + b) > noise] = 1\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = generate_linear()\n",
    "clf = select_model(x, y)\n",
    "plot_data_set(x, y)\n",
    "plot_decision_region(x[:, 0].min(), x[:, 1].min(), x[:, 0].max(), x[:, 1].max(), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_concentric(size=100, r1=1.0, r2=2.0, sigma=0.3):\n",
    "    print(\"Generating 'Concentric circles' data set\")\n",
    "    x = np.zeros((size, 2))\n",
    "    x[:size//2, 0] = sigma * np.random.randn(size//2) + r1\n",
    "    x[size//2:, 0] = sigma * np.random.randn(size//2) + r2\n",
    "    x[:, 1] = (np.random.random(size) - 0.5) * 2 * np.pi\n",
    "    y = np.hstack([np.zeros(size//2, dtype=int), np.ones(size//2, dtype=int)])\n",
    "\n",
    "    z = np.zeros((size, 2))\n",
    "    z[:, 0] = x[:, 0] * np.cos(x[:, 1])\n",
    "    z[:, 1] = x[:, 0] * np.sin(x[:, 1])\n",
    "\n",
    "    return z, y\n",
    "\n",
    "x, y = generate_concentric()\n",
    "clf = select_model(x, y)\n",
    "plot_data_set(x, y)\n",
    "plot_decision_region(x[:, 0].min(), x[:, 1].min(), x[:, 0].max(), x[:, 1].max(), clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регрессия с SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите набор данных из *titanium.csv*<br/>\n",
    "Мы будем решать задачу восстановления столбца 'y' по столбцу 'x'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните стандартную предобработку данных (z-score) и выведите их на графике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрите 3 ядра: \n",
    "* Линейное\n",
    "* Полиномиальное (degree = 3, gamma = 6, coef0 = 1)\n",
    "* RBF (gamma = 6, coef0 = 1)\n",
    "\n",
    "Во всех случаях установить ширину трубки `epsilon=0.01`\n",
    "\n",
    "Для каждого из ядер:\n",
    "1. Пусть `C = np.logspace(-2, 2, 10)`. Постройте графики зависимости ошибки от параметра $C$ (ось графика со значениями параметра $C$ должна быть в логарифмической шкале). Ошибка измеряется как средняя абсолютная ошибка. \n",
    "2. Для наулучшего параметра $С$ каждого из ядер постройте график с данными и предстазанием по svm\n",
    "\n",
    "В каких случаях возникает эффекты недообучения, переобучения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
